{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b81f3fc",
   "metadata": {},
   "source": [
    "# Part 3 - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1978fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\alindo\\downloads\\assignment3notebook\\.conda\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alindo\\downloads\\assignment3notebook\\.conda\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alindo\\downloads\\assignment3notebook\\.conda\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alindo\\downloads\\assignment3notebook\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.1 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.8/8.1 MB 23.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 23.8 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl (222 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 31.3 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 31.0 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96b3a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f2f64",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "This section performs Task 3, analyzing the Amazon Reviews 2023 dataset through visualizations and correlation analysis. DuckDB queries aggregate data from cleaned Parquet files across all categories. The analysis includes:\n",
    "\n",
    "### Star Rating Histogram: Distribution of ratings (1-5) to assess review sentiment.\n",
    "\n",
    "\n",
    "\n",
    "### Top 10 Categories by Review Count: Identifies the most reviewed categories (e.g., Amazon Home, AMAZON FASHION).\n",
    "\n",
    "\n",
    "\n",
    "### Top 10 Brands by Review Count (Excluding Unknown): Highlights popular brands (e.g., Amazon, Amazon Basics).\n",
    "\n",
    "\n",
    "\n",
    "### Average Star Rating per Year: Tracks rating trends over time (1996-2023).\n",
    "\n",
    "\n",
    "\n",
    "### Pearson Correlation (Review Length vs. Star Rating): Measures the linear relationship between review length and rating (-0.0673, indicating a weak negative correlation).\n",
    "Plots are saved to F:/sentiments/sentiments/plots/ for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c21b328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created or exists: F:\\sentiments\\sentiments\\plots\n",
      "Successfully created combined_data view\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab5594f173444e496acdcd0f36ff6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Rating Histogram Data:\n",
      "   rating      count\n",
      "0     1.0   50540693\n",
      "1     2.0   24497869\n",
      "2     3.0   35273582\n",
      "3     4.0   63361041\n",
      "4     5.0  329351567\n",
      "Star Rating Histogram saved\n",
      "Top 10 Categories Data:\n",
      "               main_category  review_count\n",
      "0                Amazon Home      84935034\n",
      "1             AMAZON FASHION      67182919\n",
      "2   Tools & Home Improvement      30723822\n",
      "3               Buy a Kindle      30255213\n",
      "4                      Books      24066763\n",
      "5  Cell Phones & Accessories      22191807\n",
      "6                 All Beauty      21635088\n",
      "7     Health & Personal Care      20811458\n",
      "8                 Automotive      18538520\n",
      "9            All Electronics      17127183\n",
      "Top 10 Categories plot saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cc8668149b48d28715010cff11a700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Brands Data:\n",
      "            brand  review_count\n",
      "0          Amazon       2655762\n",
      "1   Amazon Basics       1820180\n",
      "2         SAMSUNG       1025081\n",
      "3        Skechers        849766\n",
      "4  Amazon Renewed        831922\n",
      "5         Generic        758063\n",
      "6           Hanes        733109\n",
      "7            Sony        637319\n",
      "8          Spigen        633336\n",
      "9           Anker        619502\n",
      "Top 10 Brands plot saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b727be1866447a83fd87d821d481d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Star Rating per Year Data:\n",
      "    year  avg_rating\n",
      "0   1996    4.708333\n",
      "1   1997    4.400075\n",
      "2   1998    4.381895\n",
      "3   1999    4.310811\n",
      "4   2000    4.263917\n",
      "5   2001    4.215918\n",
      "6   2002    4.190905\n",
      "7   2003    4.150609\n",
      "8   2004    4.083347\n",
      "9   2005    4.062727\n",
      "10  2006    4.100867\n",
      "11  2007    4.186756\n",
      "12  2008    4.143521\n",
      "13  2009    4.125884\n",
      "14  2010    4.096444\n",
      "15  2011    4.090552\n",
      "16  2012    4.157622\n",
      "17  2013    4.245316\n",
      "18  2014    4.273626\n",
      "19  2015    4.287157\n",
      "20  2016    4.287941\n",
      "21  2017    4.248392\n",
      "22  2018    4.222303\n",
      "23  2019    4.280047\n",
      "24  2020    4.186949\n",
      "25  2021    4.081332\n",
      "26  2022    4.026181\n",
      "27  2023    4.062087\n",
      "Average Star Rating per Year plot saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f36edd89fc4438fad05ad734713ff78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between Review Length and Star Rating: -0.0673\n",
      "Interpretation: The correlation indicates the strength and direction of the linear relationship between review length and star rating.\n",
      "The correlation is very weak, suggesting almost no linear relationship.\n",
      "A negative value indicates that longer reviews tend to have lower ratings.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Directory and categories\n",
    "data_dir = Path(\"F:/sentiments/sentiments\")\n",
    "categories = [\n",
    "    \"All_Beauty\", \"Amazon_Fashion\", \"Appliances\", \"Arts_Crafts_and_Sewing\", \"Automotive\",\n",
    "    \"Baby_Products\", \"Beauty_and_Personal_Care\", \"Books\", \"CDs_and_Vinyl\",\n",
    "    \"Cell_Phones_and_Accessories\", \"Clothing_Shoes_and_Jewelry\", \"Digital_Music\", \"Electronics\",\n",
    "    \"Gift_Cards\", \"Grocery_and_Gourmet_Food\", \"Handmade_Products\", \"Health_and_Household\",\n",
    "    \"Health_and_Personal_Care\", \"Home_and_Kitchen\", \"Industrial_and_Scientific\", \"Kindle_Store\",\n",
    "    \"Magazine_Subscriptions\", \"Movies_and_TV\", \"Musical_Instruments\", \"Office_Products\",\n",
    "    \"Patio_Lawn_and_Garden\", \"Pet_Supplies\", \"Software\", \"Sports_and_Outdoors\",\n",
    "    \"Subscription_Boxes\", \"Tools_and_Home_Improvement\", \"Toys_and_Games\", \"Video_Games\", \"Unknown\"\n",
    "]\n",
    "\n",
    "# Output directory for plots\n",
    "output_dir = data_dir / \"plots\"\n",
    "try:\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    print(f\"Output directory created or exists: {output_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating output directory {output_dir}: {e}\")\n",
    "    raise\n",
    "\n",
    "# Create DuckDB connection\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL parquet; LOAD parquet;\")\n",
    "con.execute(\"SET memory_limit='12GB';\")  # 12GB for 14GB RAM\n",
    "con.execute(\"SET threads TO 8;\")  # Adjust to CPU cores\n",
    "\n",
    "# Combine all Parquet files\n",
    "try:\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE VIEW combined_data AS\n",
    "        SELECT\n",
    "            parent_asin,\n",
    "            rating,\n",
    "            text,\n",
    "            user_id,\n",
    "            asin,\n",
    "            categories,\n",
    "            main_category,\n",
    "            helpful_vote,\n",
    "            verified_purchase,\n",
    "            average_rating,\n",
    "            rating_number,\n",
    "            price,\n",
    "            brand,\n",
    "            review_length,\n",
    "            year,\n",
    "            sentiment\n",
    "        FROM read_parquet('{data_dir}/sentiment_*.parquet')\n",
    "    \"\"\")\n",
    "    print(\"Successfully created combined_data view\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating combined_data view: {e}\")\n",
    "    raise\n",
    "\n",
    "# a) Star Rating Histogram\n",
    "try:\n",
    "    con.execute(\"\"\"\n",
    "        SELECT rating, COUNT(*) AS count\n",
    "        FROM combined_data\n",
    "        WHERE rating IS NOT NULL AND rating BETWEEN 1 AND 5\n",
    "        GROUP BY rating\n",
    "        ORDER BY rating\n",
    "    \"\"\")\n",
    "    ratings_data = con.fetchdf()\n",
    "    print(\"Star Rating Histogram Data:\")\n",
    "    print(ratings_data)\n",
    "    if ratings_data.empty:\n",
    "        print(\"No data for Star Rating Histogram\")\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.bar(ratings_data['rating'], ratings_data['count'], color='skyblue')\n",
    "        plt.title('Star Rating Histogram')\n",
    "        plt.xlabel('Rating')\n",
    "        plt.ylabel('Number of Reviews')\n",
    "        plt.xticks([1, 2, 3, 4, 5])\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.savefig(output_dir / 'star_rating_histogram.png')\n",
    "        plt.close()\n",
    "        print(\"Star Rating Histogram saved\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in Star Rating Histogram: {e}\")\n",
    "\n",
    "# b) Top 10 Categories by Review Count\n",
    "try:\n",
    "    con.execute(\"\"\"\n",
    "        SELECT main_category, COUNT(*) AS review_count\n",
    "        FROM combined_data\n",
    "        WHERE main_category IS NOT NULL\n",
    "        GROUP BY main_category\n",
    "        ORDER BY review_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    categories_data = con.fetchdf()\n",
    "    print(\"Top 10 Categories Data:\")\n",
    "    print(categories_data)\n",
    "    if categories_data.empty:\n",
    "        print(\"No data for Top 10 Categories\")\n",
    "    else:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(categories_data['main_category'], categories_data['review_count'], color='lightgreen')\n",
    "        plt.title('Top 10 Categories by Review Count')\n",
    "        plt.xlabel('Category')\n",
    "        plt.ylabel('Review Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'top_10_categories.png')\n",
    "        plt.close()\n",
    "        print(\"Top 10 Categories plot saved\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in Top 10 Categories: {e}\")\n",
    "\n",
    "# c) Top 10 Brands by Review Count (Excluding \"Unknown\")\n",
    "try:\n",
    "    con.execute(\"\"\"\n",
    "        SELECT brand, COUNT(*) AS review_count\n",
    "        FROM combined_data\n",
    "        WHERE brand IS NOT NULL AND brand != 'Unknown'\n",
    "        GROUP BY brand\n",
    "        ORDER BY review_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    brands_data = con.fetchdf()\n",
    "    print(\"Top 10 Brands Data:\")\n",
    "    print(brands_data)\n",
    "    if brands_data.empty:\n",
    "        print(\"No data for Top 10 Brands\")\n",
    "    else:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(brands_data['brand'], brands_data['review_count'], color='salmon')\n",
    "        plt.title('Top 10 Brands by Review Count (Excluding Unknown)')\n",
    "        plt.xlabel('Brand')\n",
    "        plt.ylabel('Review Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'top_10_brands.png')\n",
    "        plt.close()\n",
    "        print(\"Top 10 Brands plot saved\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in Top 10 Brands: {e}\")\n",
    "\n",
    "# d) Average Star Rating per Year\n",
    "try:\n",
    "    con.execute(\"\"\"\n",
    "        SELECT year, AVG(rating) AS avg_rating\n",
    "        FROM combined_data\n",
    "        WHERE year IS NOT NULL AND rating IS NOT NULL\n",
    "        GROUP BY year\n",
    "        ORDER BY year\n",
    "    \"\"\")\n",
    "    trend_data = con.fetchdf()\n",
    "    print(\"Average Star Rating per Year Data:\")\n",
    "    print(trend_data)\n",
    "    if trend_data.empty:\n",
    "        print(\"No data for Average Star Rating per Year\")\n",
    "    else:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(trend_data['year'], trend_data['avg_rating'], marker='o', color='purple')\n",
    "        plt.title('Average Star Rating per Year')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Average Rating')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(output_dir / 'avg_rating_trend.png')\n",
    "        plt.close()\n",
    "        print(\"Average Star Rating per Year plot saved\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in Average Star Rating per Year: {e}\")\n",
    "\n",
    "# e) Pearson Correlation between Review Length and Star Rating\n",
    "try:\n",
    "    con.execute(\"\"\"\n",
    "        SELECT\n",
    "            CORR(review_length, rating) AS pearson_corr\n",
    "        FROM combined_data\n",
    "        WHERE review_length IS NOT NULL AND rating IS NOT NULL\n",
    "    \"\"\")\n",
    "    corr_result = con.fetchdf()\n",
    "    pearson_corr = corr_result['pearson_corr'][0]\n",
    "    print(f\"Pearson Correlation between Review Length and Star Rating: {pearson_corr:.4f}\")\n",
    "    print(\"Interpretation: The correlation indicates the strength and direction of the linear relationship between review length and star rating.\")\n",
    "    if abs(pearson_corr) < 0.1:\n",
    "        print(\"The correlation is very weak, suggesting almost no linear relationship.\")\n",
    "    elif abs(pearson_corr) < 0.3:\n",
    "        print(\"The correlation is weak, suggesting a slight linear relationship.\")\n",
    "    elif abs(pearson_corr) < 0.5:\n",
    "        print(\"The correlation is moderate, suggesting a noticeable linear relationship.\")\n",
    "    else:\n",
    "        print(\"The correlation is strong, suggesting a significant linear relationship.\")\n",
    "    if pearson_corr > 0:\n",
    "        print(\"A positive value indicates that longer reviews tend to have higher ratings.\")\n",
    "    elif pearson_corr < 0:\n",
    "        print(\"A negative value indicates that longer reviews tend to have lower ratings.\")\n",
    "    else:\n",
    "        print(\"A correlation of 0 indicates no linear relationship.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in Pearson Correlation: {e}\")\n",
    "\n",
    "# Clean up\n",
    "con.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
